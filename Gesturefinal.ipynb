{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Run the below to initialise the functions.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone.I am a bot powered by deep learning.I am capable of recognising gestures.So,here is how it works,you teach me 3 gestures,each of them one time to me and I will be able to classify them whenever you make such a gesture\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "import time\n",
    "from twilio.rest import Client\n",
    "account_sid = 'AC0b2a83c9d01a580c33a3c4bf70254d42'\n",
    "auth_token = '96efd127b2de93f3a86f8fcb9ab146b8'\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()\n",
    "PATH = \"/Users/prashanthsateesh/desktop/keras-oneshot-master\" #CHANGE THIS - path where the pickled data is stored\n",
    "import cv2,time\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import argparse\n",
    "import cmath\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"Hello everyone.I am a bot powered by deep learning.I am capable of recognising gestures.So,here is how it works,you teach me 3 gestures,each of them one time to me and I will be able to classify them whenever you make such a gesture\")\n",
    "print(\"\\n\")\n",
    "\n",
    "def calltoteachgesture1():\n",
    "    teachgesture(1)\n",
    "def calltoteachgesture2():\n",
    "    teachgesture(2)\n",
    "def calltoteachgesture3():\n",
    "    teachgesture(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def teachgesture(gesturenumber):\n",
    "    print(\"Teach me the \"+str(gesturenumber)+\"st \"+ \"gesture.\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    hand_cascade = cv2.CascadeClassifier('hand4.xml')\n",
    "    array2=[]\n",
    "    array1=[]\n",
    "\n",
    "    c=0\n",
    "\n",
    "    z = np.ones([720,1280,3], np.uint8)*255\n",
    "    x = np.ones([720,1280,3], np.uint8)*255\n",
    "    img = np.zeros((720,1280), np.uint8)\n",
    "    img=img+255\n",
    "    thickness = 15\n",
    "    thickness2 = 45\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hands = hand_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "        ##drawing of rectangular box around fist and filled circle at the centre of the box\n",
    "        for(x,y,w,h) in hands:\n",
    "            if (w*h>20000):\n",
    "                cv2.rectangle(frame, (x,y),(x+w, y+h),(0, 255, 0), 2)\n",
    "                l = int(w/2)\n",
    "                m = int(h/2)\n",
    "                cv2.circle(frame, (x+l,y+m), 10, (0, 0, 255), -1)\n",
    "        \n",
    "                if c==0 :\n",
    "                    prev_x = x+l\n",
    "                    prev_y = y+m\n",
    "                    \n",
    "                elif c>0 :\n",
    "                    d = abs(cmath.sqrt((x+l-prev_x)*(x+l-prev_x)+(y+m-prev_y)*(y+m-prev_y)));\n",
    "                      \n",
    "                    if d<75 :\n",
    "                        array1=(x+l,y+m)\n",
    "                        prev_x = x+l\n",
    "                        prev_y = y+m\n",
    "\n",
    "                c = c+1;\n",
    "        \n",
    "        if array1!=[]:\n",
    "            array2=array2+[array1]\n",
    "                  \n",
    "        for i in range(1, len(array2)):\n",
    "            cv2.line(frame, (array2[i-1][0],array2[i-1][1]), (array2[i][0],array2[i][1]), (0, 0, 255), thickness)\n",
    "            cv2.line(img, (array2[i-1][0],array2[i-1][1]), (array2[i][0],array2[i][1]), (1, 1, 1), thickness2)\n",
    "\n",
    "        frame = cv2.flip( frame, 1 )\n",
    "        cv2.imshow('Frame',frame)\n",
    "        key=cv2.waitKey(1)\n",
    "        if key==ord('q'):\n",
    "            cap.release()\n",
    "            break\n",
    "    print(\"If you want to save this gesture press Y else press N to reteach\")\n",
    "    option=str(input(\"Enter your choice: \"))\n",
    "    if option=='y':\n",
    "        fnumber= open(str(gesturenumber)+\"/\"+\"filenumber.txt\",\"r\")\n",
    "\n",
    "\n",
    "        #img = np.zeros((720,1280), np.uint8)\n",
    "        #img=img+255\n",
    "        pts = np.array(array2, np.int32)\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        #cv2.polylines(img,[pts],True,(0,0,0))\n",
    "        #cv2.line(img, (pts), (0, 0, 0), thickness)\n",
    "\n",
    "        img = cv2.flip( img, 1 )\n",
    "\n",
    "        if fnumber.readline()=='':\n",
    "            fnumber.close()\n",
    "            fnumber= open(str(gesturenumber)+\"/\"+\"filenumber.txt\",\"w\")\n",
    "            cv2.imwrite(str(gesturenumber)+\"/\"+str(1)+\".png\",img)\n",
    "            foo = Image.open(str(gesturenumber)+\"/\"+str(1)+\".png\")\n",
    "            foo = foo.resize((105,105),Image.ANTIALIAS)\n",
    "            foo.save(str(gesturenumber)+\"/\"+str(1)+\".png\",quality=100)\n",
    "            fnumber.write(\"1\\n\")\n",
    "            fnumber.close()\n",
    "        else:\n",
    "            fnumber= open(str(gesturenumber)+\"/\"+\"filenumber.txt\",\"r\")\n",
    "\n",
    "            temp=fnumber.readline()\n",
    "            fnumber.close()\n",
    "            temp=int(temp)\n",
    "            temp=temp+1\n",
    "            fnumber= open(str(gesturenumber)+\"/\"+\"filenumber.txt\",\"w\")\n",
    "            cv2.imwrite(str(gesturenumber)+\"/\"+str(temp)+\".png\",img)\n",
    "            foo = Image.open(str(gesturenumber)+\"/\"+str(temp)+\".png\")\n",
    "            foo = foo.resize((105,105),Image.ANTIALIAS)\n",
    "            foo.save(str(gesturenumber)+\"/\"+str(temp)+\".png\",quality=100)\n",
    "            fnumber.write(str(temp)+\"\\n\")\n",
    "            fnumber.close()\n",
    "    elif option=='n':\n",
    "        calltoteachgesture1()\n",
    "def gesture():\n",
    "    print(\"Make the geture that you want to classify\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    hand_cascade = cv2.CascadeClassifier('hand4.xml')\n",
    "    array2=[]\n",
    "    array1=[]\n",
    "\n",
    "    c=0\n",
    "\n",
    "    z = np.ones([720,1280,3], np.uint8)*255\n",
    "    x = np.ones([720,1280,3], np.uint8)*255\n",
    "    img = np.zeros((720,1280), np.uint8)\n",
    "    img=img+255\n",
    "    thickness = 15\n",
    "    thickness2 = 45\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hands = hand_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "        ##drawing of rectangular box around fist and filled circle at the centre of the box\n",
    "        for(x,y,w,h) in hands:\n",
    "            if (w*h>20000):\n",
    "                cv2.rectangle(frame, (x,y),(x+w, y+h),(0, 255, 0), 2)\n",
    "                l = int(w/2)\n",
    "                m = int(h/2)\n",
    "                cv2.circle(frame, (x+l,y+m), 10, (0, 0, 255), -1)\n",
    "        \n",
    "                if c==0 :\n",
    "                    prev_x = x+l\n",
    "                    prev_y = y+m\n",
    "                    \n",
    "                elif c>0 :\n",
    "                    d = abs(cmath.sqrt((x+l-prev_x)*(x+l-prev_x)+(y+m-prev_y)*(y+m-prev_y)));\n",
    "                      \n",
    "                    if d<75 :\n",
    "                        array1=(x+l,y+m)\n",
    "                        prev_x = x+l\n",
    "                        prev_y = y+m\n",
    "\n",
    "                c = c+1;\n",
    "        \n",
    "        if array1!=[]:\n",
    "            array2=array2+[array1]\n",
    "                  \n",
    "        for i in range(1, len(array2)):\n",
    "            cv2.line(frame, (array2[i-1][0],array2[i-1][1]), (array2[i][0],array2[i][1]), (0, 0, 255), thickness)\n",
    "            cv2.line(img, (array2[i-1][0],array2[i-1][1]), (array2[i][0],array2[i][1]), (1, 1, 1), thickness2)\n",
    "\n",
    "        frame = cv2.flip( frame, 1 )\n",
    "        cv2.imshow('Frame',frame)\n",
    "        key=cv2.waitKey(1)\n",
    "        if key==ord('q'):\n",
    "            cap.release()\n",
    "            break\n",
    "    \n",
    "    fnumber= open(str(4)+\"/\"+\"filenumber.txt\",\"r\")\n",
    "\n",
    "\n",
    "        #img = np.zeros((720,1280), np.uint8)\n",
    "        #img=img+255\n",
    "    pts = np.array(array2, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "        #cv2.polylines(img,[pts],True,(0,0,0))\n",
    "        #cv2.line(img, (pts), (0, 0, 0), thickness)\n",
    "\n",
    "    img = cv2.flip( img, 1 )\n",
    "\n",
    "    if fnumber.readline()=='':\n",
    "            fnumber.close()\n",
    "            fnumber= open(str(4)+\"/\"+\"filenumber.txt\",\"w\")\n",
    "            cv2.imwrite(str(4)+\"/\"+str(1)+\".png\",img)\n",
    "            foo = Image.open(str(4)+\"/\"+str(1)+\".png\")\n",
    "            foo = foo.resize((105,105),Image.ANTIALIAS)\n",
    "            foo.save(str(4)+\"/\"+str(1)+\".png\",quality=100)\n",
    "            fnumber.write(\"1\\n\")\n",
    "            fnumber.close()\n",
    "    else:\n",
    "            fnumber= open(str(4)+\"/\"+\"filenumber.txt\",\"r\")\n",
    "\n",
    "            temp=fnumber.readline()\n",
    "            fnumber.close()\n",
    "            temp=int(temp)\n",
    "            temp=temp+1\n",
    "            fnumber= open(str(4)+\"/\"+\"filenumber.txt\",\"w\")\n",
    "            cv2.imwrite(str(4)+\"/\"+str(temp)+\".png\",img)\n",
    "            foo = Image.open(str(4)+\"/\"+str(temp)+\".png\")\n",
    "            foo = foo.resize((105,105),Image.ANTIALIAS)\n",
    "            foo.save(str(4)+\"/\"+str(temp)+\".png\",quality=100)\n",
    "            fnumber.write(str(temp)+\"\\n\")\n",
    "            fnumber.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Call below to teach gestures.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teach me the 1st gesture.\n",
      "If you want to save this gesture press Y else press N to reteach\n",
      "Enter your choice: y\n",
      "Teach me the 2st gesture.\n",
      "If you want to save this gesture press Y else press N to reteach\n",
      "Enter your choice: y\n",
      "Teach me the 3st gesture.\n",
      "If you want to save this gesture press Y else press N to reteach\n",
      "Enter your choice: y\n",
      "All gestures have been learnt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calltoteachgesture1()\n",
    "calltoteachgesture2()\n",
    "calltoteachgesture3()\n",
    "print(\"All gestures have been learnt.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Call below to execute one of the applications.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make a gesture to exectue any one of the applications.\n",
      "\n",
      "Make the geture that you want to classify\n",
      "The application to execute is: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Make a gesture to exectue any one of the applications.\\n\")\n",
    "gesture()\n",
    "img = Image.open( '/Users/prashanthsateesh/desktop/keras-oneshot-master/4/'+'1' + '.png' )\n",
    "data = np.array( img, dtype='uint8' )\n",
    "input1=np.asarray(data).reshape(1,105,105,1)\n",
    "siamese_net.load_weights( \"/Users/prashanthsateesh/desktop/keras-oneshot-master/weights_4\")\n",
    "sumgesture1=0\n",
    "final=[]\n",
    "for letter in os.listdir(\"/Users/prashanthsateesh/desktop/keras-oneshot-master/1\"):\n",
    "    if letter.find(\".DS_Store\")==-1 & letter.find(\"filenumber\")==-1:\n",
    "        img2 = Image.open(\"/Users/prashanthsateesh/desktop/keras-oneshot-master/1/\"+str(letter))\n",
    "        data2 = np.array(img2, dtype='uint8' )\n",
    "        input2=np.asarray(data2).reshape(1,105,105,1)\n",
    "        inputs=[input1,input2]\n",
    "        final=final+[siamese_net.predict(inputs)[0][0]]\n",
    "for letter in os.listdir(\"/Users/prashanthsateesh/desktop/keras-oneshot-master/2\"):\n",
    "    if letter.find(\".DS_Store\")==-1 & letter.find(\"filenumber\")==-1:\n",
    "        img2 = Image.open(\"/Users/prashanthsateesh/desktop/keras-oneshot-master/2/\"+str(letter))\n",
    "        data2 = np.array(img2, dtype='uint8' )\n",
    "        input2=np.asarray(data2).reshape(1,105,105,1)\n",
    "        inputs=[input1,input2]\n",
    "        final=final+[siamese_net.predict(inputs)[0][0]]\n",
    "for letter in os.listdir(\"/Users/prashanthsateesh/desktop/keras-oneshot-master/3\"):\n",
    "    if letter.find(\".DS_Store\")==-1 & letter.find(\"filenumber\")==-1:\n",
    "        img2 = Image.open(\"/Users/prashanthsateesh/desktop/keras-oneshot-master/3/\"+str(letter))\n",
    "        data2 = np.array(img2, dtype='uint8' )\n",
    "        input2=np.asarray(data2).reshape(1,105,105,1)\n",
    "        inputs=[input1,input2]\n",
    "        final=final+[siamese_net.predict(inputs)[0][0]]\n",
    "print(\"The application to execute is: \"+str(final.index(max(final))+1))\n",
    "if(final.index(max(final))+1==1):\n",
    "   \n",
    "    call = client.calls.create(\n",
    "                        url='http://demo.twilio.com/docs/voice.xml',\n",
    "                        to='+918582908625',\n",
    "                        from_='+12483270277'\n",
    "                    )\n",
    "\n",
    "    print(call.sid)\n",
    "   \n",
    "       \n",
    "elif(final.index(max(final))+1==2):\n",
    "   \n",
    "    message = client.messages \\\n",
    "                .create(\n",
    "                     body=\"Call Dr.Amartya immediately..\",\n",
    "                     from_='+12483270277',\n",
    "                     to='+918582908625'\n",
    "                 )\n",
    "elif(final.index(max(final))+1==3):\n",
    " \n",
    "             arduinoData=serial.Serial('/dev/cu.usbmodem1411',9600)\n",
    "\n",
    "             def led_on():\n",
    "                arduinoData.write(b'1')\n",
    "             time.sleep(2)\n",
    "             led_on()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
